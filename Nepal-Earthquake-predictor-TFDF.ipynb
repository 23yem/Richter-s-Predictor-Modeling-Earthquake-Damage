{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to my Richter's Predictor Nepal Earthquake Damage Predictor Tensor Flow Decision Forest (TFDF) Model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default code from Kaggle Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying some important libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(\"Tensorflow:\", tf.__version__)\n",
    "\n",
    "# import kerastuner as kt\n",
    "# print(\"kerastuner:\", kt.__version__)\n",
    "\n",
    "# import keras_tuner as kt2\n",
    "# print(\"keras_tuner:\", kt2.__version__)\n",
    "\n",
    "# import platform\n",
    "# print(\"Python:\", platform.python_version())\n",
    "\n",
    "# import numpy as np\n",
    "# print(\"numpy:\", np.__version__)\n",
    "\n",
    "# import pandas as pd\n",
    "# print(\"pandas:\", pd.__version__)\n",
    "\n",
    "# import sklearn\n",
    "# print(\"sklearn version:\", sklearn.__version__)\n",
    "\n",
    "# import sklearn\n",
    "# print(\"sklearn path:\", sklearn.__path__)\n",
    "\n",
    "# import matplotlib\n",
    "# print(\"matplotlib:\", matplotlib.__version__)\n",
    "\n",
    "# import seaborn as sns\n",
    "# print(\"seaborn:\", sns.__version__)\n",
    "\n",
    "# # WARNING:tensorflow:From c:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
    "\n",
    "# # Tensorflow: 2.15.0\n",
    "# # C:\\Users\\Micha\\AppData\\Local\\Temp\\ipykernel_6936\\1753711907.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
    "# #   import kerastuner as kt\n",
    "# # kerastuner: 1.0.5\n",
    "# # keras_tuner: 1.3.5\n",
    "# # Python: 3.10.11\n",
    "# # numpy: 1.24.3\n",
    "# # pandas: 2.1.4\n",
    "# # sklearn version: 1.2.2\n",
    "# # sklearn path: ['c:\\\\Users\\\\Micha\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\sklearn']\n",
    "# # matplotlib: 3.8.2\n",
    "# # seaborn: 0.13.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global random seed to make sure we can replicate any model that we create (no randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_values are the features (X), and train_labels is the target/label (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = pd.read_csv(\"train_values.csv\")\n",
    "# train_Y = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "\n",
    "n_train = int(len(pd.read_csv(\"train_values.csv\")) * 0.01)\n",
    "train_X = pd.read_csv(\"train_values.csv\").head(n_train)\n",
    "train_Y = pd.read_csv(\"train_labels.csv\").head(n_train)\n",
    "\n",
    "test_values = pd.read_csv(\"test_values.csv\")\n",
    "\n",
    "# print(\"train labels:\\n\", train_Y.head())\n",
    "\n",
    "# print(\"train values:\\n\", train_X.head())\n",
    "      \n",
    "# print(\"test_values:\\n\", test_values.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I want to find out which features to use since there are so many. Here are some common data science techniques:\n",
    "\n",
    "1. **Correlation Matrix with Heatmap**: Correlation states how the features are related to each other or the target variable. You can use a heatmap to visualize the correlation matrix.\n",
    "\n",
    "2. **Univariate Selection**: Statistical tests can be used to select those features that have the strongest relationship with the output variable. The scikit-learn library provides the `SelectKBest` class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "\n",
    "3. **Recursive Feature Elimination (RFE)**: RFE is a popular feature selection method that fits a model and removes the weakest feature (or features) until the specified number of features is reached.\n",
    "\n",
    "4. **Feature Importance**: You can get the feature importance of each feature of your dataset by using the feature importance property of the model. For example, Decision Trees models in the scikit-learn library offer an importance property that can be accessed directly.\n",
    "\n",
    "For categorical features, you can convert them into numerical values using techniques like One-Hot Encoding or Label Encoding before applying these feature selection techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, I will try RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from lightgbm import LGBMRegressor #Lightgbm is a great gradient boosting model for large amount of data\n",
    "\n",
    "# # Assuming X is your feature set and y is the target value\n",
    "# X = train_X.drop('building_id', axis=1)\n",
    "# X = pd.get_dummies(X)\n",
    "\n",
    "# y = train_Y.drop('building_id', axis=1)\n",
    "# y = np.ravel(y) # converting dataframe to a one-dimensional array using the ravel function from numpy\n",
    "\n",
    "# estimator = LGBMRegressor(verbose = 0, random_state = 42)  # It's best to find the best model for you\n",
    "# selector = RFE(estimator, step=1)\n",
    "# selector = selector.fit(X, y)\n",
    "\n",
    "# # Assuming 'X' is your DataFrame with the feature data\n",
    "# feature_names = X.columns\n",
    "\n",
    "# # Map the feature names to the support array, which tells you which features were selected\n",
    "# support_dict = dict(zip(feature_names, selector.support_))\n",
    "\n",
    "# # Get the selected features\n",
    "# selected_features = [feature for feature, support in support_dict.items() if support]\n",
    "\n",
    "# # Print the selected features\n",
    "# print(\"Selected features:\\n\", selected_features)\n",
    "\n",
    "# # ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
    "# # 'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone',\n",
    "# # 'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', \n",
    "# # 'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other', 'count_families', 'has_secondary_use', \n",
    "# # 'land_surface_condition_n', 'land_surface_condition_o', 'foundation_type_h', 'foundation_type_r', 'foundation_type_u', 'roof_type_n', \n",
    "# # 'roof_type_q', 'roof_type_x', 'ground_floor_type_f', 'ground_floor_type_v', 'ground_floor_type_x', 'other_floor_type_q', 'position_s',\n",
    "# # 'plan_configuration_u']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # The feature ranking, such that ranking_[i] corresponds to the ranking position of the i-th feature. \n",
    "# # Selected features are assigned rank 1.\n",
    "# # Map the feature names to the ranking array\n",
    "# ranking_dict = dict(zip(feature_names, selector.ranking_))\n",
    "# print(ranking_dict)\n",
    "\n",
    "\n",
    "# # [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2 18 10 31\n",
    "# #  27 33 28 25 30  6  1  1  3  1  8  1  1  5  1  1  1  1 34  1  1 16  9  1\n",
    "# #  23  7  4 14  1 29 15 20 17 35 32 24 21 13 26  1 11 22 12 19]\n",
    "\n",
    "\n",
    "# # {'geo_level_1_id': 1, 'geo_level_2_id': 1, 'geo_level_3_id': 1, 'count_floors_pre_eq': 1, 'age': 1, 'area_percentage': 1, \n",
    "# #  'height_percentage': 1, 'has_superstructure_adobe_mud': 1, 'has_superstructure_mud_mortar_stone': 1, 'has_superstructure_stone_flag': 1, \n",
    "# #  'has_superstructure_cement_mortar_stone': 1, 'has_superstructure_mud_mortar_brick': 1, 'has_superstructure_cement_mortar_brick': 1, \n",
    "# #  'has_superstructure_timber': 1, 'has_superstructure_bamboo': 1, 'has_superstructure_rc_non_engineered': 1, 'has_superstructure_rc_engineered': 1, \n",
    "# #  'has_superstructure_other': 1, 'count_families': 1, 'has_secondary_use': 1, 'has_secondary_use_agriculture': 2, 'has_secondary_use_hotel': 18, \n",
    "# #  'has_secondary_use_rental': 10, 'has_secondary_use_institution': 31, 'has_secondary_use_school': 27, 'has_secondary_use_industry': 33, \n",
    "# #  'has_secondary_use_health_post': 28, 'has_secondary_use_gov_office': 25, 'has_secondary_use_use_police': 30, 'has_secondary_use_other': 6, \n",
    "# #  'land_surface_condition_n': 1, 'land_surface_condition_o': 1, 'land_surface_condition_t': 3, 'foundation_type_h': 1, 'foundation_type_i': 8, \n",
    "# #  'foundation_type_r': 1, 'foundation_type_u': 1, 'foundation_type_w': 5, 'roof_type_n': 1, 'roof_type_q': 1, 'roof_type_x': 1, \n",
    "# #  'ground_floor_type_f': 1, 'ground_floor_type_m': 34, 'ground_floor_type_v': 1, 'ground_floor_type_x': 1, 'ground_floor_type_z': 16, \n",
    "# #  'other_floor_type_j': 9, 'other_floor_type_q': 1, 'other_floor_type_s': 23, 'other_floor_type_x': 7, 'position_j': 4, 'position_o': 14, \n",
    "# #  'position_s': 1, 'position_t': 29, 'plan_configuration_a': 15, 'plan_configuration_c': 20, 'plan_configuration_d': 17, 'plan_configuration_f': 35, \n",
    "# #  'plan_configuration_m': 32, 'plan_configuration_n': 24, 'plan_configuration_o': 21, 'plan_configuration_q': 13, 'plan_configuration_s': 26, \n",
    "# #  'plan_configuration_u': 1, 'legal_ownership_status_a': 11, 'legal_ownership_status_r': 22, 'legal_ownership_status_v': 12, \n",
    "# #  'legal_ownership_status_w': 19}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "New features:\n",
      " ['land_surface_condition_n', 'land_surface_condition_o', 'foundation_type_h', 'foundation_type_r', 'foundation_type_u', 'roof_type_n', 'roof_type_q', 'roof_type_x', 'ground_floor_type_f', 'ground_floor_type_v', 'ground_floor_type_x', 'other_floor_type_q', 'position_s', 'plan_configuration_u']\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "features = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
    "'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone',\n",
    "'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', \n",
    "'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other', 'count_families', 'has_secondary_use', \n",
    "'land_surface_condition_n', 'land_surface_condition_o', 'foundation_type_h', 'foundation_type_r', 'foundation_type_u', 'roof_type_n', \n",
    "'roof_type_q', 'roof_type_x', 'ground_floor_type_f', 'ground_floor_type_v', 'ground_floor_type_x', 'other_floor_type_q', 'position_s',\n",
    "'plan_configuration_u']\n",
    "\n",
    "print(len(features))\n",
    "\n",
    "\n",
    "# Find out which features are created through one-hot-encoding\n",
    "import pandas as pd\n",
    "\n",
    "# Load the original data\n",
    "original_data = pd.read_csv('train_values.csv')\n",
    "\n",
    "# Get the original feature names\n",
    "original_features = original_data.columns\n",
    "\n",
    "# Check which features are not in the original data\n",
    "new_features = [feature for feature in features if feature not in original_features]\n",
    "\n",
    "# Print the new features\n",
    "print(\"New features:\\n\", new_features)\n",
    "\n",
    "\n",
    "#Manually remove the one-hot-encoding that pd.get_dummies() used on categorial \n",
    "features_before_dummies = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
    "'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone',\n",
    "'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', \n",
    "'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other', 'count_families', 'has_secondary_use', \n",
    "'land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type','other_floor_type', 'position','plan_configuration']\n",
    "\n",
    "print(len(features_before_dummies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis from ChatGPT-4 (second way to find best features):\n",
    "\n",
    "The categorical variables in the features dataset have been successfully encoded. Now, let's look at the correlation of these features with the `damage_grade`:\n",
    "\n",
    "#### Correlation with `damage_grade`\n",
    "The correlation values range between -1 and 1. A value closer to 1 indicates a strong positive correlation, meaning that as the feature increases, the `damage_grade` tends to increase. Conversely, a value closer to -1 indicates a strong negative correlation, where an increase in the feature leads to a decrease in `damage_grade`. Values around 0 imply weak or no linear correlation.\n",
    "\n",
    "#### Top Positively Correlated Features:\n",
    "- `has_superstructure_mud_mortar_stone`\n",
    "- `count_floors_pre_eq`\n",
    "- Other features like `legal_ownership_status`, `has_superstructure_stone_flag`, etc., also show positive correlation but to a lesser extent.\n",
    "\n",
    "#### Top Negatively Correlated Features:\n",
    "- `has_superstructure_cement_mortar_brick`\n",
    "- `ground_floor_type`\n",
    "- `has_superstructure_rc_engineered`\n",
    "- Other features like `roof_type`, `has_superstructure_rc_non_engineered`, etc., also show negative correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the selected features based on the correlation threshold (of 0.05):\n",
    "\n",
    "1. `has_superstructure_mud_mortar_stone`\n",
    "2. `count_floors_pre_eq`\n",
    "3. `legal_ownership_status`\n",
    "4. `has_superstructure_stone_flag`\n",
    "5. `count_families`\n",
    "6. `has_superstructure_adobe_mud`\n",
    "7. `position`\n",
    "8. `has_superstructure_cement_mortar_stone`\n",
    "9. `has_superstructure_bamboo`\n",
    "10. `has_superstructure_timber`\n",
    "11. `geo_level_1_id`\n",
    "12. `has_secondary_use`\n",
    "13. `has_secondary_use_rental`\n",
    "14. `has_secondary_use_hotel`\n",
    "15. `foundation_type`\n",
    "16. `area_percentage`\n",
    "17. `has_superstructure_rc_non_engineered`\n",
    "18. `roof_type`\n",
    "19. `has_superstructure_rc_engineered`\n",
    "20. `ground_floor_type`\n",
    "21. `has_superstructure_cement_mortar_brick`\n",
    "\n",
    "These features were chosen because they have a correlation with the target variable `damage_grade` greater than the specified threshold of 0.05 (in absolute value). You can use these features for building your predictive model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = [\n",
    "    \"has_superstructure_mud_mortar_stone\",\n",
    "    \"count_floors_pre_eq\",\n",
    "    \"legal_ownership_status\",\n",
    "    \"has_superstructure_stone_flag\",\n",
    "    \"count_families\",\n",
    "    \"has_superstructure_adobe_mud\",\n",
    "    \"position\",\n",
    "    \"has_superstructure_cement_mortar_stone\",\n",
    "    \"has_superstructure_bamboo\",\n",
    "    \"has_superstructure_timber\",\n",
    "    \"geo_level_1_id\",\n",
    "    \"has_secondary_use\",\n",
    "    \"has_secondary_use_rental\",\n",
    "    \"has_secondary_use_hotel\",\n",
    "    \"foundation_type\",\n",
    "    \"area_percentage\",\n",
    "    \"has_superstructure_rc_non_engineered\",\n",
    "    \"roof_type\",\n",
    "    \"has_superstructure_rc_engineered\",\n",
    "    \"ground_floor_type\",\n",
    "    \"has_superstructure_cement_mortar_brick\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third, I will try SelectKBest to find best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "# # Create the SelectKBest with the f_classif function. You can set the parameter \"k\" equal to a number if you want to limit the amount of features\n",
    "# selector = SelectKBest(f_classif, k = 20) # Getting the 20 best features\n",
    "\n",
    "# # Assuming X is your feature set and y is the target value\n",
    "# X = train_X.drop('building_id', axis=1)\n",
    "# X = pd.get_dummies(X)\n",
    "\n",
    "# y = train_Y.drop('building_id', axis=1)\n",
    "# y = np.ravel(y) # converting dataframe to a one-dimensional array using the ravel function from numpy\n",
    "\n",
    "\n",
    "# # Fit the selector to the data\n",
    "# selector.fit(X, y)\n",
    "\n",
    "# # Get the boolean mask of the selected features\n",
    "# mask = selector.get_support()\n",
    "\n",
    "# # Get the names of the selected features\n",
    "# selected_features = X.columns[mask]\n",
    "\n",
    "# # Convert the Index object to a list\n",
    "# features3 = selected_features.tolist()\n",
    "\n",
    "# print(features3)\n",
    "\n",
    "# # ['geo_level_1_id', 'count_floors_pre_eq', 'area_percentage', 'has_superstructure_mud_mortar_stone', 'has_superstructure_cement_mortar_brick', \n",
    "# #  'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_secondary_use_hotel', 'has_secondary_use_rental', \n",
    "# #  'foundation_type_i', 'foundation_type_r', 'foundation_type_u', 'foundation_type_w', 'roof_type_n', 'roof_type_x', 'ground_floor_type_f', \n",
    "# #  'ground_floor_type_v', 'other_floor_type_j', 'other_floor_type_q', 'other_floor_type_s']\n",
    "\n",
    "\n",
    "# # Get the scores\n",
    "# scores = selector.scores_\n",
    "\n",
    "# # Create a DataFrame with the scores\n",
    "# features_scores = pd.DataFrame({'Feature': X.columns, 'Score': scores})\n",
    "\n",
    "# # Sort the DataFrame by score in descending order\n",
    "# features_scores = features_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# # print the best 20 features\n",
    "# print(features_scores[0:19])\n",
    "\n",
    "# #                                    Feature         Score\n",
    "# # 35                       foundation_type_r  23787.275036\n",
    "# # 43                     ground_floor_type_v  20782.933584\n",
    "# # 40                             roof_type_x  16891.038184\n",
    "# # 8      has_superstructure_mud_mortar_stone  16490.386507\n",
    "# # 34                       foundation_type_i  16385.772905\n",
    "# # 12  has_superstructure_cement_mortar_brick  11120.193268\n",
    "# # 48                      other_floor_type_s  10507.484572\n",
    "# # 41                     ground_floor_type_f  10151.525359\n",
    "# # 16        has_superstructure_rc_engineered   7757.593854\n",
    "# # 47                      other_floor_type_q   7378.599061\n",
    "# # 15    has_superstructure_rc_non_engineered   4721.916051\n",
    "# # 37                       foundation_type_w   4568.674306\n",
    "# # 46                      other_floor_type_j   4533.708398\n",
    "# # 36                       foundation_type_u   2972.409108\n",
    "# # 0                           geo_level_1_id   2657.791274\n",
    "# # 3                      count_floors_pre_eq   2544.836052\n",
    "# # 5                          area_percentage   2529.046730\n",
    "# # 38                             roof_type_n   1776.396178\n",
    "# # 21                 has_secondary_use_hotel   1537.672773\n",
    "\n",
    "# # ...\n",
    "\n",
    "# # 22                has_secondary_use_rental   1342.099336\n",
    "# # 64                legal_ownership_status_a   1166.606551\n",
    "# # 19                       has_secondary_use    841.802928\n",
    "# # 39                             roof_type_q    761.885856\n",
    "# # 7             has_superstructure_adobe_mud    739.412821\n",
    "# # 13               has_superstructure_timber    659.199014\n",
    "# # 9            has_superstructure_stone_flag    576.438023\n",
    "# # 14               has_superstructure_bamboo    538.551492\n",
    "# # 66                legal_ownership_status_v    536.308634\n",
    "# # 11     has_superstructure_mud_mortar_brick    531.784659\n",
    "# # 63                    plan_configuration_u    515.087147\n",
    "# # 10  has_superstructure_cement_mortar_stone    478.844199\n",
    "# # 18                          count_families    476.562914\n",
    "# # 56                    plan_configuration_d    378.234531\n",
    "# # 53                              position_t    373.594539\n",
    "# # 6                        height_percentage    370.173817\n",
    "# # 20           has_secondary_use_agriculture    289.462856\n",
    "# # 1                           geo_level_2_id    264.447807\n",
    "# # 49                      other_floor_type_x    244.432657\n",
    "# # 4                                      age    219.626253\n",
    "# # 33                       foundation_type_h    209.425818\n",
    "# # 32                land_surface_condition_t    201.698101\n",
    "# # 30                land_surface_condition_n    182.152148\n",
    "# # 61                    plan_configuration_q    165.370472\n",
    "# # 23           has_secondary_use_institution    146.731486\n",
    "# # 17                has_superstructure_other    142.014204\n",
    "# # 50                              position_j    136.783490\n",
    "# # 67                legal_ownership_status_w    116.039402\n",
    "# # 52                              position_s    110.038831\n",
    "# # 55                    plan_configuration_c     75.423022\n",
    "# # 51                              position_o     75.104323\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3 = ['geo_level_1_id', 'count_floors_pre_eq', 'area_percentage', 'has_superstructure_mud_mortar_stone', 'has_superstructure_cement_mortar_brick', \n",
    " 'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_secondary_use_hotel', 'has_secondary_use_rental', \n",
    " 'foundation_type_i', 'foundation_type_r', 'foundation_type_u', 'foundation_type_w', 'roof_type_n', 'roof_type_x', 'ground_floor_type_f', \n",
    " 'ground_floor_type_v', 'other_floor_type_j', 'other_floor_type_q', 'other_floor_type_s']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if there are any missing values in the data. If so, we have to do imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in train_X: 0\n",
      "Number of missing values in train_Y: 0\n",
      "Number of missing values in test_values: 0\n"
     ]
    }
   ],
   "source": [
    "missing_train_X = train_X.isnull().sum().sum()\n",
    "print(\"Number of missing values in train_X:\", missing_train_X)\n",
    "\n",
    "missing_train_Y = train_Y.isnull().sum().sum()\n",
    "print(\"Number of missing values in train_Y:\", missing_train_Y)\n",
    "\n",
    "missing_test_values = test_values.isnull().sum().sum()\n",
    "print(\"Number of missing values in test_values:\", missing_test_values )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 0 missing values in each dataframe, we don't have to do imputation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we have 3 different list of features (features, features2, and features3), which I found using RFE. Data Analysis ChatGPT-4, and SelectKBest respectively\n",
    "\n",
    "#### Now, I have to turn one-hot-encode the data using pd.get_dummies, and I'll be creating 3 seperate train_X, one for each list of possible best features. And also on the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. testX1 for the RFE features\n",
    "# Since the features from RFE are the one-hot-encoded features, we have to apply features after doing pd.get_dummies()\n",
    "\n",
    "trainX1 = pd.get_dummies(train_X)\n",
    "trainX1 = trainX1[features]\n",
    "\n",
    "\n",
    "# 2. testX2 for the Data Analysis ChatGPT-4\n",
    "# Since the features from Data Analysis are from the original feature set, we have to apply the features before doing pd.get_dummies()\n",
    "\n",
    "trainX2 = train_X[features2]\n",
    "trainX2 = pd.get_dummies(trainX2)\n",
    "\n",
    "\n",
    "\n",
    "# 3. testX3 for the SelectKBest\n",
    "# Since the features from RFE are the one-hot-encoded features, we have to apply features after doing pd.get_dummies()\n",
    "\n",
    "trainX3 = pd.get_dummies(train_X)\n",
    "trainX3 = trainX3[features3]\n",
    "\n",
    "\n",
    "\n",
    "# 4. Do pd.get_dummies() on test data. I will create a seperate test_data for each feature selection, since each test_data needs to have a certain set of features\n",
    "\n",
    "test_data1 = pd.get_dummies(test_values)\n",
    "test_data1 = test_data1[features + ['building_id'] ]\n",
    "\n",
    "test_data2 = test_values[features2 + ['building_id'] ]\n",
    "test_data2 = pd.get_dummies(test_data2)\n",
    "\n",
    "test_data3 = pd.get_dummies(test_values)\n",
    "test_data3 = test_data3[features3 + ['building_id'] ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's important to do pd.get_dummies() before doing the train_valid_test split. Now we can do the split\n",
    "I have to do train_valid_test split three times, one for each different train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. train_valid_test split for train_X1\n",
    "train_X1, test_X1, train_Y1, test_Y1 = train_test_split(trainX1, train_Y, test_size=0.3, random_state = 42) # split into training (70%) and a test set (30%)\n",
    "\n",
    "valid_X1, test_X1, valid_Y1, test_Y1 = train_test_split(test_X1, test_Y1, test_size = 0.5, random_state = 42) # split test set into a validation (15%) and test set (15%)\n",
    "\n",
    "\n",
    "# 2. train_valid_test split for train_X2\n",
    "train_X2, test_X2, train_Y2, test_Y2 = train_test_split(trainX2, train_Y, test_size=0.3, random_state = 42) # split into training (70%) and a test set (30%)\n",
    "\n",
    "valid_X2, test_X2, valid_Y2, test_Y2 = train_test_split(test_X2, test_Y2, test_size = 0.5, random_state = 42) # split test set into a validation (15%) and test set (15%)\n",
    "\n",
    "\n",
    "# 3. train_valid_test split for train_X3\n",
    "train_X3, test_X3, train_Y3, test_Y3 = train_test_split(trainX3, train_Y, test_size=0.3, random_state = 42) # split into training (70%) and a test set (30%)\n",
    "\n",
    "valid_X3, test_X3, valid_Y3, test_Y3 = train_test_split(test_X3, test_Y3, test_size = 0.5, random_state = 42) # split test set into a validation (15%) and test set (15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the Normalizing Scaler**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different Normalization Scalers:\n",
    "\n",
    "1. **MinMaxScaler**: This scaler scales and translates each feature individually such that it is in the given range on the training set, e.g., between zero and one.\n",
    "\n",
    "\n",
    "2. **StandardScaler**: This scaler standardizes features by removing the mean and scaling to unit variance.\n",
    "\n",
    "\n",
    "3. **RobustScaler**: This scaler scales features using statistics that are robust to outliers. It uses the Interquartile Range (IQR) to scale the data, making it a better choice for when the data has outliers.\n",
    "\n",
    "\n",
    "4. **Normalizer**: This scaler scales individual samples to have unit norm. This scaler works on the rows, not the columns!\n",
    "\n",
    "\n",
    "5. **MaxAbsScaler**: This scaler scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.\n",
    "\n",
    "\n",
    "Remember, the choice of scaler can depend on your specific dataset and the machine learning algorithm that you're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've actually decided to not do normalization since almost all the columns are categorial columns, and the non-categorial columns are mostly normalized already in the dataset, so there's no need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've actually decided to not do normalization since almost all the columns are categorial columns, and the non-categorial columns are mostly normalized already in the dataset, so there's no need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change all the data to float32 so that it can be converted into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = train_X1.astype('float32')\n",
    "valid_X1 = valid_X1.astype('float32')\n",
    "test_X1 = test_X1.astype('float32')\n",
    "\n",
    "train_Y1 = train_Y1.astype('float32')\n",
    "valid_Y1 = valid_Y1.astype('float32')\n",
    "test_Y1 = test_Y1.astype('float32')\n",
    "\n",
    "train_X2 = train_X2.astype('float32')\n",
    "valid_X2 = valid_X2.astype('float32')\n",
    "test_X2 = test_X2.astype('float32')\n",
    "\n",
    "train_Y2 = train_Y2.astype('float32')\n",
    "valid_Y2 = valid_Y2.astype('float32')\n",
    "test_Y2 = test_Y2.astype('float32')\n",
    "\n",
    "train_X3 = train_X3.astype('float32')\n",
    "valid_X3 = valid_X3.astype('float32')\n",
    "test_X3 = test_X3.astype('float32')\n",
    "\n",
    "train_Y3 = train_Y3.astype('float32')\n",
    "valid_Y3 = valid_Y3.astype('float32')\n",
    "test_Y3 = test_Y3.astype('float32')\n",
    "\n",
    "test_data1 = test_data1.astype('float32')\n",
    "test_data2 = test_data2.astype('float32')\n",
    "test_data3 = test_data3.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 for TFDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using automatic hyper parameter space since I don't know what the good hyperparameters are\n",
    "\n",
    "The dataset might be too big for TFDF. In that case, try and cut data in half or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpb7cyid92 as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.231733. Found 2606 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:40.034452\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-11 22:06:54.4419 EST kernel.cc:1233] Loading model from path /tmp/tmpb7cyid92/model/ with prefix 8ea0622780a54347\n",
      "[INFO 24-01-11 22:06:54.5288 EST decision_forest.cc:660] Model loaded with 300 root(s), 28818 node(s), and 34 input feature(s).\n",
      "[INFO 24-01-11 22:06:54.5288 EST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 24-01-11 22:06:54.5288 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "h1\n",
      "INFO:tensorflow:Assets written to: model1_RF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1_RF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "score                                             0.673062\n",
      "evaluation_time                                  39.882017\n",
      "best                                                  True\n",
      "split_axis                                  SPARSE_OBLIQUE\n",
      "sparse_oblique_projection_density_factor               5.0\n",
      "sparse_oblique_normalization                       MIN_MAX\n",
      "sparse_oblique_weights                              BINARY\n",
      "categorical_algorithm                                 CART\n",
      "winner_take_all                                       true\n",
      "max_depth                                               12\n",
      "min_examples                                            40\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# %pip install wurlitzer -U -qq # This will automatically install wurlitzer when you run this notebook\n",
    "\n",
    "\n",
    "\n",
    "if os.path.isdir(\"_model1_RF\"): # If the model already exists (inside a directory named model3_RF)\n",
    "    model1 = load_model(\"model1_RF\") # set model3 equal to this already existing model\n",
    "\n",
    "\n",
    "else: # if the model1 doesn't exist already, create it\n",
    "    train_Y1_temp = train_Y1['damage_grade'] - 1  \n",
    "    valid_Y1_temp = valid_Y1['damage_grade'] - 1\n",
    "    test_Y1_temp = test_Y1['damage_grade'] - 1\n",
    "\n",
    "\n",
    "    train_RF_X = pd.concat([train_X1, valid_X1, test_X1], ignore_index=True)  \n",
    "    train_RF_Y = pd.concat([train_Y1_temp, valid_Y1_temp , test_Y1_temp], ignore_index=True)\n",
    "    train_RF = pd.concat([train_RF_X, train_RF_Y], axis = 1, ignore_index = False)\n",
    "\n",
    "    # test_RF_X = test_X\n",
    "    # test_RF_Y = test_Y\n",
    "    # test_RF = pd.concat([test_RF_X, test_RF_Y], axis = 1, ignore_index = False)\n",
    "\n",
    "    train_data_RF = tfdf.keras.pd_dataframe_to_tf_dataset(train_RF, label = \"damage_grade\", task = tfdf.keras.Task.CLASSIFICATION)\n",
    "\n",
    "    # test_data_RF = tfdf.keras.pd_dataframe_to_tf_dataset(test_RF, label = \"Survived\")\n",
    "\n",
    "\n",
    "    #This is a TensorFlow Decision Forest Tuner. I am using RandomSearch since it might be the only one, and also because I want it to be fast\n",
    "    tuner1 = tfdf.tuner.RandomSearch(num_trials=1, use_predefined_hps=True, trial_num_threads = 8) \n",
    "\n",
    "\n",
    "    #Now I make the model and do .fit() on it since .fit() will cause the tuner to run and find the best hyperparameters\n",
    "    # MAKE SURE TO SET THE \"tuner\" PARAMETER IN ORDER FOR THE TUNER TO RUN\n",
    "    model1 = tfdf.keras.RandomForestModel(tuner = tuner1, compute_oob_performances = True, compute_oob_variable_importances = True, random_seed = 42, verbose = 1, task = tfdf.keras.Task.CLASSIFICATION)\n",
    "\n",
    "    model1.compile([\"accuracy\"])\n",
    "\n",
    "    model1.fit(train_data_RF, verbose = 1)\n",
    "\n",
    "    print(\"h1\")\n",
    "\n",
    "    model1.save(\"model1_RF\")\n",
    "\n",
    "    print(\"h\")\n",
    "\n",
    "    # Display the tuning logs\n",
    "    tuning_logs = model1.make_inspector().tuning_logs()\n",
    "    tuning_logs.head()\n",
    "\n",
    "\n",
    "    # Make sure to either save the model or save all the hyper parameters of the model since we used RandomSearch() \n",
    "    # here so if we run the code again, we will get a totally different model!\n",
    "\n",
    "    # Best hyper-parameters\n",
    "    print(tuning_logs[tuning_logs.best].iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "    # these lines below will save the best hyperparameters to a JSON file that will be stored in a file, so that I can always look back at it incase I want to replicate this model and it's results\n",
    "    import json\n",
    "\n",
    "    best_hyperparameters = tuning_logs[tuning_logs.best].iloc[0].to_dict() # convert to a dictionary so that you can convert it to a JSON\n",
    "\n",
    "    # Save the best hyperparameters to a file\n",
    "    with open('hyperparameters_TFDF_model1.json', 'w') as f:\n",
    "        json.dump(best_hyperparameters, f)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # these lines basically saves the \".summary()\" method into a file so that I can use it later if I want to replicate this model\n",
    "    import sys\n",
    "\n",
    "    with open('model1_RF_summary.txt', 'w') as f: \n",
    "        old_stdout = sys.stdout  # Save the original standard output\n",
    "        sys.stdout = f  # Redirect standard output to the file\n",
    "\n",
    "        model1.summary()  # This will be written to the file. Basically, by changing the standard output, this will print the summary in my file INSTEAD of inside the jupyter notebook. The standard output dictates where the print outputs go\n",
    "\n",
    "        sys.stdout = old_stdout  # Restore the original standard output\n",
    "\n",
    "# It took 50 seconds to do one trial with 1/100 of the original training data\n",
    "\n",
    "\n",
    "# Note: you may need to restart the kernel to use updated packages.\n",
    "# Use /tmp/tmp7wvzg4q6 as temporary training directory\n",
    "# Reading training dataset...\n",
    "# Training dataset read in 0:00:02.396684. Found 712 examples.\n",
    "# Training model...\n",
    "# Model trained in 0:01:54.848762\n",
    "# Compiling model...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a cool way to see the best trial performance in a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(tuning_logs[\"score\"], label=\"current trial\")\n",
    "plt.plot(tuning_logs[\"score\"].cummax(), label=\"best trial\")\n",
    "plt.xlabel(\"Tuning step\")\n",
    "plt.ylabel(\"Tuning score\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Model 1. Score: 65.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-11 22:06:55.3617 EST kernel.cc:1233] Loading model from path model1_RF/assets/ with prefix 8ea0622780a54347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/87 [..............................] - ETA: 8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-11 22:07:03.2526 EST decision_forest.cc:660] Model loaded with 300 root(s), 28818 node(s), and 34 input feature(s).\n",
      "[INFO 24-01-11 22:07:03.2527 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 3s 38ms/step\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model1 = load_model(\"model1_RF\")\n",
    "\n",
    "\n",
    "# Separate building_ids and features in the test data\n",
    "competition_test_building_ids = test_data1['building_id']\n",
    "competition_test_X = test_data1.drop('building_id', axis=1)\n",
    "\n",
    "\n",
    "#  Convert the test data to a tf dataset\n",
    "test_data_RF = tfdf.keras.pd_dataframe_to_tf_dataset(competition_test_X, task=tfdf.keras.Task.CLASSIFICATION)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model1.predict(test_data_RF)\n",
    "\n",
    "# Get the class with the highest probability for each instance\n",
    "predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "# Since the competition expects labels in the range 1-3, add 1 to the predictions\n",
    "predictions = predictions + 1\n",
    "\n",
    "# Create a DataFrame for submission\n",
    "submission = pd.DataFrame({\n",
    "    'building_id': competition_test_building_ids,\n",
    "    'damage_grade': predictions\n",
    "})\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('submission_TFDF_1.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
