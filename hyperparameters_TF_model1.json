{"input_units": 152, "input_activation": "relu", "n_layers": 4, "hidden_units_0": 32, "hidden_activation_0": "sigmoid", "regularization_0": 0.03, "dropout_rate": 0.30000000000000004, "optimizer": "sgd", "hidden_units_1": 32, "hidden_activation_1": "relu", "regularization_1": 0.03, "hidden_units_2": 92, "hidden_activation_2": "sigmoid", "regularization_2": 0.1, "hidden_units_3": 152, "hidden_activation_3": "sigmoid", "regularization_3": 0.09}